{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# #validate\n",
    "# with open(r'data\\1. 400-100 dataset\\midi_crnn.json','r') as load_f:\n",
    "#     dataset = json.load(load_f)\n",
    "#     validate_1 = np.asarray(dataset[\"y_v_train\"])\n",
    "                            \n",
    "# with open(r'data\\1. 400-100 dataset\\wav_crnn.json','r') as load_f:\n",
    "#     dataset = json.load(load_f)\n",
    "#     validate_2 = np.asarray(dataset[\"y_v_train\"])\n",
    "\n",
    "# validate_2 = validate_2.reshape(validate_1.shape)\n",
    "# print((validate_1==validate_2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60, 128, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 60, 128, 8)   80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 60, 128, 8)   32          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 60, 1024)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 60, 8)        8200        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 60, 8)        8200        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 60, 16)       864         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 60, 16)       864         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 60, 1)        17          bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 60, 1)        17          bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 60)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 60)           0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 18,274\n",
      "Trainable params: 18,258\n",
      "Non-trainable params: 16\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# crnn - model\n",
    "def Crnn(conv_filters=8,vaDense = 8,Gru=8):\n",
    "    input_data = layers.Input((60, 128,1))\n",
    "    x = layers.Conv2D(conv_filters, 3, activation='relu', padding=\"same\")(input_data)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Reshape((60,128*conv_filters))(x)\n",
    "\n",
    "    arousal = layers.Dense(vaDense, activation='linear')(x)\n",
    "    arousal = layers.Bidirectional(layers.GRU(Gru,return_sequences = True,activation = 'tanh'))(arousal)\n",
    "    arousal = layers.Dense(1, activation='linear')(arousal)\n",
    "    arousal = layers.Flatten()(arousal)\n",
    "\n",
    "    volence = layers.Dense(vaDense, activation='linear')(x)\n",
    "    volence = layers.Bidirectional(layers.GRU(Gru,return_sequences = True,activation = 'tanh'))(volence)\n",
    "    volence = layers.Dense(1, activation='linear')(volence)\n",
    "    volence = layers.Flatten()(volence)\n",
    "\n",
    "    model = keras.Model(inputs=input_data, outputs=[arousal, volence])\n",
    "    \n",
    "    model.compile(loss = [\"mean_squared_error\",\"mean_squared_error\"], optimizer='adam')\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n",
    "model_crnn = Crnn()\n",
    "model_crnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi crnn - load dataset\n",
    "import json\n",
    "with open(r'data\\1. 400-100 dataset\\midi_crnn.json','r') as load_f:\n",
    "    dataset = json.load(load_f)\n",
    "    x_train = np.asarray(dataset[\"x_train\"])\n",
    "    x_test = np.asarray(dataset[\"x_test\"])\n",
    "    y_a_train = np.asarray(dataset[\"y_a_train\"])\n",
    "    y_a_test = np.asarray(dataset[\"y_a_test\"])\n",
    "    y_v_train = np.asarray(dataset[\"y_v_train\"])\n",
    "    y_v_test = np.asarray(dataset[\"y_v_test\"])\n",
    "\n",
    "# data reshape\n",
    "x_train = x_train.reshape(400,60,128,1)\n",
    "x_test = x_test.reshape(100,60,128,1)\n",
    "y_a_train = y_a_train.reshape(400,60)\n",
    "y_a_test = y_a_test.reshape(100,60)\n",
    "y_v_train = y_v_train.reshape(400,60)\n",
    "y_v_test = y_v_test.reshape(100,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  4 13:35:00 2020\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 8 , batch= 5 is:  0.12400154829025269\n",
      "Wed Nov  4 13:36:59 2020 \n",
      "\n",
      "min loss= 0.12400154829025269\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 8 , batch= 10 is:  0.11874869346618652\n",
      "Wed Nov  4 13:38:31 2020 \n",
      "\n",
      "min loss= 0.11874869346618652\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 8 , batch= 15 is:  0.12517922788858413\n",
      "Wed Nov  4 13:40:04 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 16 , batch= 5 is:  0.12185034632682801\n",
      "Wed Nov  4 13:42:24 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 16 , batch= 10 is:  0.1271989643573761\n",
      "Wed Nov  4 13:43:56 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 16 , batch= 15 is:  0.1188790237903595\n",
      "Wed Nov  4 13:45:28 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 32 , batch= 5 is:  0.1348132860660553\n",
      "Wed Nov  4 13:47:43 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 32 , batch= 10 is:  0.14537263989448548\n",
      "Wed Nov  4 13:49:19 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 32 , batch= 15 is:  0.12127460718154907\n",
      "Wed Nov  4 13:50:47 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 16 , Gru= 8 , batch= 5 is:  0.13239843964576722\n",
      "Wed Nov  4 13:52:56 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 16 , Gru= 8 , batch= 10 is:  0.1274106079339981\n",
      "Wed Nov  4 13:54:30 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 16 , Gru= 8 , batch= 15 is:  0.13553990185260772\n",
      "Wed Nov  4 13:56:05 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 16 , Gru= 16 , batch= 5 is:  0.13127535164356233\n",
      "Wed Nov  4 13:58:19 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 16 , Gru= 16 , batch= 10 is:  0.13076700568199157\n",
      "Wed Nov  4 13:59:54 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 16 , Gru= 16 , batch= 15 is:  0.13326117217540742\n",
      "Wed Nov  4 14:01:25 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 16 , Gru= 32 , batch= 5 is:  0.11980886697769165\n",
      "Wed Nov  4 14:03:36 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 16 , Gru= 32 , batch= 10 is:  0.1309565556049347\n",
      "Wed Nov  4 14:05:11 2020 \n",
      "\n",
      "loss on c_f= 8 , vaDense= 16 , Gru= 32 , batch= 15 is:  0.13067204058170317\n",
      "Wed Nov  4 14:06:39 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 8 , Gru= 8 , batch= 5 is:  0.14935738682746888\n",
      "Wed Nov  4 14:09:16 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 8 , Gru= 8 , batch= 10 is:  0.12682278752326964\n",
      "Wed Nov  4 14:11:15 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 8 , Gru= 8 , batch= 15 is:  0.12440451502799987\n",
      "Wed Nov  4 14:13:11 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 8 , Gru= 16 , batch= 5 is:  0.12952805161476136\n",
      "Wed Nov  4 14:15:41 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 8 , Gru= 16 , batch= 10 is:  0.13666816234588622\n",
      "Wed Nov  4 14:17:34 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 8 , Gru= 16 , batch= 15 is:  0.1242203152179718\n",
      "Wed Nov  4 14:19:16 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 8 , Gru= 32 , batch= 5 is:  0.1261324417591095\n",
      "Wed Nov  4 14:22:39 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 8 , Gru= 32 , batch= 10 is:  0.1152189016342163\n",
      "Wed Nov  4 14:25:51 2020 \n",
      "\n",
      "min loss= 0.1152189016342163\n",
      "loss on c_f= 16 , vaDense= 8 , Gru= 32 , batch= 15 is:  0.12743616998195648\n",
      "Wed Nov  4 14:27:44 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 16 , Gru= 8 , batch= 5 is:  0.1271995025873184\n",
      "Wed Nov  4 14:29:56 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 16 , Gru= 8 , batch= 10 is:  0.1350169861316681\n",
      "Wed Nov  4 14:31:35 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 16 , Gru= 8 , batch= 15 is:  0.13106985211372377\n",
      "Wed Nov  4 14:33:21 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 16 , Gru= 16 , batch= 5 is:  0.1250000900030136\n",
      "Wed Nov  4 14:35:42 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 16 , Gru= 16 , batch= 10 is:  0.12707137286663056\n",
      "Wed Nov  4 14:37:22 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 16 , Gru= 16 , batch= 15 is:  0.1305280113220215\n",
      "Wed Nov  4 14:38:59 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 16 , Gru= 32 , batch= 5 is:  0.12826237797737122\n",
      "Wed Nov  4 14:41:24 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 16 , Gru= 32 , batch= 10 is:  0.1309774848818779\n",
      "Wed Nov  4 14:43:26 2020 \n",
      "\n",
      "loss on c_f= 16 , vaDense= 16 , Gru= 32 , batch= 15 is:  0.11916469931602477\n",
      "Wed Nov  4 14:45:17 2020 \n",
      "\n",
      "WARNING:tensorflow:From E:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Failed to create a directory: data\u0002. Best Model\best_crnn_mid; Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-073bb2ec59dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     validation_data=(x_test, [y_a_test,y_v_test]),verbose=0)\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mmodel_crnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\\2. Best Model\\best_crnn_mid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    973\u001b[0m     \"\"\"\n\u001b[0;32m    974\u001b[0m     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m--> 975\u001b[1;33m                       signatures, options)\n\u001b[0m\u001b[0;32m    976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    113\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[1;32m--> 115\u001b[1;33m                           signatures, options)\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[0;32m     72\u001b[0m   \u001b[1;31m# default learning phase placeholder.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0msave_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m    897\u001b[0m   \u001b[1;31m# the checkpoint, copy assets into the assets directory, and write out the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m   \u001b[1;31m# SavedModel proto itself.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m   \u001b[0mutils_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_or_create_variables_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m   \u001b[0mobject_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\utils_impl.py\u001b[0m in \u001b[0;36mget_or_create_variables_dir\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[0mvariables_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_variables_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mvariables_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m   \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m   \u001b[0mrecursive_create_dir_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m   \"\"\"\n\u001b[1;32m--> 453\u001b[1;33m   \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Failed to create a directory: data\u0002. Best Model\best_crnn_mid; Invalid argument"
     ]
    }
   ],
   "source": [
    "print(time.asctime(time.localtime(time.time())))\n",
    "min_loss_mid = 99999999999999\n",
    "min_config_mid = {'cf':0,'vaDense':0,'gru':0,'bs':0}\n",
    "for conv_filters in (8,16):\n",
    "    for vaDense in (8,16):\n",
    "        for Gru in (8,16,32):\n",
    "            for batch_size in (5,10,15):\n",
    "                model_crnn = Crnn(conv_filters,vaDense,Gru)\n",
    "                model_crnn.fit(\n",
    "                    x_train,[y_a_train,y_v_train], \n",
    "                    epochs=15, batch_size=batch_size,\n",
    "                    validation_data=(x_test, [y_a_test,y_v_test]),verbose=0)\n",
    "                # verbose means shows log or not 0:nothing 1: epoch result + bar 2:only epoch result\n",
    "                print('loss on c_f=',conv_filters,\", vaDense=\",vaDense,\", Gru=\",Gru,\", batch=\",batch_size,\"is: \",\n",
    "                      model_crnn.evaluate(x_test,[y_a_test,y_v_test], verbose=0)[0])\n",
    "                print(time.asctime(time.localtime(time.time())),\"\\n\")\n",
    "                if model_crnn.evaluate(x_test,[y_a_test,y_v_test], verbose=0)[0]<min_loss_mid:\n",
    "                    min_loss_mid = model_crnn.evaluate(x_test,[y_a_test,y_v_test], verbose=0)[0]\n",
    "                    min_config_mid['cf']= conv_filters\n",
    "                    min_config_mid['vaDense'] = vaDense\n",
    "                    min_config_mid['gru'] = Gru\n",
    "                    min_config_mid['bs'] = batch_size\n",
    "                    print('min loss=', min_loss_mid)\n",
    "                    \n",
    "model_crnn = Crnn(min_config_mid['cf'],min_config_mid['vaDense'],min_config_mid['gru'])\n",
    "model_crnn.fit(\n",
    "    x_train,[y_a_train,y_v_train], \n",
    "    epochs=15, batch_size=min_config_mid['bs'],\n",
    "    validation_data=(x_test, [y_a_test,y_v_test]),verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data\\2. Best Model\\best_crnn_mid\\assets\n",
      "{'cf': 16, 'vaDense': 8, 'gru': 32, 'bs': 10}\n"
     ]
    }
   ],
   "source": [
    "model_crnn.save(r\"data\\2. Best Model\\best_crnn_mid\")\n",
    "print(min_config_mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# wav crnn - load dataset\n",
    "import json\n",
    "with open(r'data\\1. 400-100 dataset\\wav_crnn.json','r') as load_f:\n",
    "    dataset = json.load(load_f)\n",
    "    x_train = np.asarray(dataset[\"x_train\"])\n",
    "    x_test = np.asarray(dataset[\"x_test\"])\n",
    "    y_a_train = np.asarray(dataset[\"y_a_train\"])\n",
    "    y_a_test = np.asarray(dataset[\"y_a_test\"])\n",
    "    y_v_train = np.asarray(dataset[\"y_v_train\"])\n",
    "    y_v_test = np.asarray(dataset[\"y_v_test\"])\n",
    "    \n",
    "x_train = x_train.reshape(400,60,128,1)\n",
    "x_test = x_test.reshape(100,60,128,1)\n",
    "y_a_train = y_a_train.reshape(400,60)\n",
    "y_a_test = y_a_test.reshape(100,60)\n",
    "y_v_train = y_v_train.reshape(400,60)\n",
    "y_v_test = y_v_test.reshape(100,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  4 17:25:21 2020\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 8 , batch= 5 is:  0.10005115538835525\n",
      "Wed Nov  4 17:28:26 2020 \n",
      "\n",
      "min loss= 0.10005115538835525\n",
      "loss on c_f= 8 , vaDense= 8 , Gru= 8 , batch= 10 is:  0.08709792584180832\n",
      "Wed Nov  4 17:30:20 2020 \n",
      "\n",
      "min loss= 0.08709792584180832\n"
     ]
    }
   ],
   "source": [
    "print(time.asctime(time.localtime(time.time())))\n",
    "min_loss_wav = 99999999999999\n",
    "min_config_wav = {'cf':0,'vaDense':0,'gru':0,'bs':0}\n",
    "for conv_filters in (8,16):\n",
    "    for vaDense in (8,16):\n",
    "        for Gru in (8,16,32):\n",
    "            for batch_size in (5,10,15):\n",
    "                model_crnn = Crnn(conv_filters,vaDense,Gru)\n",
    "                model_crnn.fit(\n",
    "                    x_train,[y_a_train,y_v_train], \n",
    "                    epochs=15, batch_size=batch_size,\n",
    "                    validation_data=(x_test, [y_a_test,y_v_test]),verbose=0)\n",
    "                # verbose means shows log or not 0:nothing 1: epoch result + bar 2:only epoch result\n",
    "                print('loss on c_f=',conv_filters,\", vaDense=\",vaDense,\", Gru=\",Gru,\", batch=\",batch_size,\"is: \",\n",
    "                      model_crnn.evaluate(x_test,[y_a_test,y_v_test], verbose=0)[0])\n",
    "                print(time.asctime(time.localtime(time.time())),\"\\n\")\n",
    "                if model_crnn.evaluate(x_test,[y_a_test,y_v_test], verbose=0)[0]<min_loss_wav:\n",
    "                    min_loss_wav = model_crnn.evaluate(x_test,[y_a_test,y_v_test], verbose=0)[0]\n",
    "                    min_config_wav['cf']= conv_filters\n",
    "                    min_config_wav['vaDense'] = vaDense\n",
    "                    min_config_wav['gru'] = Gru\n",
    "                    min_config_wav['bs'] = batch_size\n",
    "                    print('min loss=', min_loss_wav)\n",
    "                    \n",
    "model_crnn = Crnn(min_config_wav['cf'],min_config_wav['vaDense'],min_config_wav['gru'])\n",
    "model_crnn.fit(\n",
    "    x_train,[y_a_train,y_v_train], \n",
    "    epochs=15, batch_size=min_config_wav['bs'],\n",
    "    validation_data=(x_test, [y_a_test,y_v_test]),verbose=0)\n",
    "\n",
    "model_crnn.save(\"data\\2. Best Model\\best_crnn_wav\")\n",
    "print(min_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

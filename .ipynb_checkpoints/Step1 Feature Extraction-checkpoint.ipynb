{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import librosa\n",
    "import random\n",
    "# pretty midi: https://craffel.github.io/pretty-midi/#pretty-midi-timesignature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avilable_list=[]\n",
    "# this list record the availavle data we can used for both midi and wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##filter the data not available for midi\n",
    "work_dir = r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\mid-aud-to-midi-bearaudiotool.com-mp3-to-midi'\n",
    "\n",
    "available_list=[]\n",
    "\n",
    "for parent, dirnames, filenames in os.walk(work_dir,  followlinks=True):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".mid\"):\n",
    "            file_path = os.path.join(parent, filename)\n",
    "            midi_data = pretty_midi.PrettyMIDI(file_path)\n",
    "            proll = midi_data.instruments[0].get_piano_roll(fs=100).transpose()\n",
    "            #fs: Sampling frequency of the columns, i.e. each column is spaced apart by 1./fs seconds\n",
    "            index = os.path.splitext(os.path.splitext(filename)[0])[0]\n",
    "            \n",
    "            print(index,filename,len(midi_data.instruments),proll.shape)\n",
    "            \n",
    "            if (proll.shape[0]>4550)or (proll.shape[0]<4450):\n",
    "                print(\"error too long or too short\")\n",
    "                continue\n",
    "            \n",
    "            print(\"available\")\n",
    "            available_list.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#filter the data not available for wav\n",
    "work_dir = r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\audio'\n",
    "output_dir = r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\wav-audio'\n",
    "AudioSegment.converter = r'E:\\ffmpeg\\bin\\ffmpeg.exe'\n",
    "\n",
    "print(len(available_list))\n",
    "for parent, dirnames, filenames in os.walk(work_dir,  followlinks=True):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".mp3\"):\n",
    "            index = os.path.splitext(filename)[0]\n",
    "            print(index)\n",
    "            if index in available_list:\n",
    "                wavsong = AudioSegment.from_mp3(os.path.join(parent, filename))\n",
    "                if len(wavsong)<45000:\n",
    "                    available_list.remove(index)\n",
    "                    \n",
    "print(len(available_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# random sampling 400+100\n",
    "random.seed(42)\n",
    "sample_data = random.sample(available_list,500) # randomly sample 500 data\n",
    "train_list = sample_data[0:400] # 400 as train\n",
    "test_list = sample_data[400:] # 100 as test\n",
    "print(train_list,\"\\n\",test_list)\n",
    "with open(r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\400-100-dataset\\list.json', 'w+') as f:\n",
    "    json.dump({'train': train_list,'test':test_list},f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# open the lable csv\n",
    "import json\n",
    "arousal_dict={}\n",
    "with open(r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\v-a values\\arousal.json','r') as load_f:\n",
    "    arousal_dict = json.load(load_f)\n",
    "    \n",
    "with open(r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\v-a values\\volence.json','r') as load_f:\n",
    "    volence_dict = json.load(load_f)\n",
    "\n",
    "#validata our loading\n",
    "print(arousal_dict[\"2\"]['5'],volence_dict[\"10\"]['37'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extraFeature_wav(parent_path,filename,output_dir,x_data,y_a,y_v,arousal_dict,volence_dict,frame_size,step):\n",
    "    wavsong = AudioSegment.from_mp3(os.path.join(parent_path, filename))\n",
    "\n",
    "    one_data = []\n",
    "\n",
    "    for i in range(60):\n",
    "        outputpath = os.path.join(output_dir,index+'-'+str(i)+\".wav\")\n",
    "        wavsong[(15000+500*i):(15500+500*i)].export(outputpath, format=\"wav\")\n",
    "        y, sr = librosa.load(outputpath, sr=None)\n",
    "        os.remove(outputpath)\n",
    "\n",
    "        fragment = np.array(\n",
    "                        np.log(\n",
    "                            librosa.feature.melspectrogram(\n",
    "                                y, sr, n_mels=128,n_fft=int(sr*frame_size), hop_length=int(sr*step)\n",
    "                            )\n",
    "                        ).transpose())\n",
    "        fragment = fragment[np.newaxis,:]\n",
    "\n",
    "        if one_data==[]:\n",
    "            one_data = fragment.copy()                    \n",
    "        else:\n",
    "            one_data = np.vstack([one_data,fragment.copy()])\n",
    "\n",
    "    #packaged one data\n",
    "    one_data = one_data[np.newaxis,:]\n",
    "    if x_data == []:\n",
    "        x_data = one_data.copy()\n",
    "    else:\n",
    "        x_data = np.vstack([x_data,one_data.copy()])\n",
    "        \n",
    "    for i in range(60):\n",
    "        y_a.append(arousal_dict[index][str(i)])\n",
    "        y_v.append(volence_dict[index][str(i)])\n",
    "        \n",
    "        \n",
    "    return x_data,y_a,y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# then we will build 4 dataset: wav+cnn, wav+crnn, midi+cnn, wav+crnn\n",
    "\n",
    "# wav+cnn, shape = (400+100)*3000*128\n",
    "# We should rewrite as a function...um\n",
    "AudioSegment.converter = r'E:\\ffmpeg\\bin\\ffmpeg.exe'\n",
    "work_dir = r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\audio'\n",
    "output_dir = r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\wav-audio'\n",
    "\n",
    "x_train_data = []\n",
    "x_test_data =[]\n",
    "y_a_train_data = []\n",
    "y_a_test_data = []\n",
    "y_v_train_data = []\n",
    "y_v_test_data = []\n",
    "\n",
    "for parent, dirnames, filenames in os.walk(work_dir,  followlinks=True):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".mp3\"):\n",
    "            index = os.path.splitext(filename)[0]\n",
    "            if index in train_list:\n",
    "                print(\"train\",index)\n",
    "                (x_train_data,y_a_train_data,y_v_train_data) = extraFeature_wav(parent,filename,output_dir,\n",
    "                                                x_train_data,y_a_train_data,y_v_train_data,\n",
    "                                                arousal_dict,volence_dict,\n",
    "                                                0.025,0.010)\n",
    "                print(x_train_data.shape,\"train\",index)\n",
    "                \n",
    "                \n",
    "            \n",
    "            if index in test_list:\n",
    "                (x_test_data,y_a_test_data,y_v_test_data) = extraFeature_wav(parent,filename,output_dir,\n",
    "                                                x_test_data,y_a_test_data,y_v_test_data,\n",
    "                                                arousal_dict,volence_dict,\n",
    "                                                0.025,0.010)\n",
    "                    \n",
    "                print(x_test_data.shape,\"test\",index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#save the wav+cnn\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "with open(r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\400-100-dataset\\wav_cnn.json', 'w+') as f:\n",
    "    json.dump({'x_train':x_train_data,\n",
    "               'x_test':x_test_data,\n",
    "               'y_a_train':y_a_train_data,\n",
    "               'y_a_test':y_a_test_data,\n",
    "               'y_v_train':y_v_train_data,\n",
    "               'y_v_test':y_v_test_data},f,cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# wav+crnn\n",
    "# wav+crnn, shape = (400+100)*60*128\n",
    "AudioSegment.converter = r'E:\\ffmpeg\\bin\\ffmpeg.exe'\n",
    "work_dir = r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\audio'\n",
    "output_dir = r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\wav-audio'\n",
    "\n",
    "x_train_data = []\n",
    "x_test_data =[]\n",
    "y_a_train_data = []\n",
    "y_a_test_data = []\n",
    "y_v_train_data = []\n",
    "y_v_test_data = []\n",
    "\n",
    "for parent, dirnames, filenames in os.walk(work_dir,  followlinks=True):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".mp3\"):\n",
    "            index = os.path.splitext(filename)[0]\n",
    "            if index in train_list:\n",
    "                (x_train_data,y_a_train_data,y_v_train_data) = extraFeature_wav(parent,filename,output_dir,\n",
    "                    x_train_data,y_a_train_data,y_v_train_data,\n",
    "                    arousal_dict,volence_dict,\n",
    "                    0.5,1)\n",
    "                print(x_train_data.shape,\"train\",index)\n",
    "                \n",
    "                \n",
    "            \n",
    "            if index in test_list:\n",
    "                (x_test_data,y_a_test_data,y_v_test_data) = extraFeature_wav(parent,filename,output_dir,\n",
    "                    x_test_data,y_a_test_data,y_v_test_data,\n",
    "                    arousal_dict,volence_dict,\n",
    "                    0.5,1)\n",
    "                    \n",
    "                print(x_test_data.shape,\"test\",index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#save the wav+crnn\n",
    "\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "with open(r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\400-100-dataset\\wav_crnn.json', 'w+') as f:\n",
    "    json.dump({'x_train':x_train_data,\n",
    "               'x_test':x_test_data,\n",
    "               'y_a_train':y_a_train_data,\n",
    "               'y_a_test':y_a_test_data,\n",
    "               'y_v_train':y_v_train_data,\n",
    "               'y_v_test':y_v_test_data},f,cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extraFeature_midi_cnn(parent,filename,output_dir,x_data,y_a,y_v,arousal_dict,volence_dict,fs,num_frame):\n",
    "    file_path = os.path.join(parent, filename)\n",
    "    midi_data = pretty_midi.PrettyMIDI(file_path)\n",
    "    proll = midi_data.instruments[0].get_piano_roll(fs=fs).transpose()\n",
    "    #fs: Sampling frequency of the columns, i.e. each column is spaced apart by 1./fs seconds\n",
    "    index = os.path.splitext(os.path.splitext(filename)[0])[0]\n",
    "            \n",
    "    print(index,filename,len(midi_data.instruments),proll.shape)\n",
    "            \n",
    "    if proll.shape[0] > 90*num_frame:\n",
    "        proll = proll[:90*num_frame,:128]\n",
    "    while proll.shape[0]< 90*num_frame:\n",
    "        lastrow = proll[proll.shape[0]-1].copy()\n",
    "        proll=np.vstack([proll,lastrow])\n",
    "    proll = proll.reshape(90,num_frame,128)\n",
    "    proll = proll[30:90]\n",
    "    proll = proll[np.newaxis,:]\n",
    "            \n",
    "    if x_data==[]:\n",
    "        x_data = proll.copy()\n",
    "    else:\n",
    "        x_data = np.vstack([x_data,proll.copy()])\n",
    "                \n",
    "    arousal_data = []\n",
    "    for i in range(0,60):\n",
    "        arousal_data.append(arousal_dict[index][str(i)])\n",
    "    y_a.append(arousal_data)\n",
    "            \n",
    "    volence_data = []\n",
    "    for i in range(0,60):\n",
    "        volence_data.append(volence_dict[index][str(i)])\n",
    "    y_v.append(volence_data)\n",
    "        \n",
    "        \n",
    "    return x_data,y_a,y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# midi+cnn\n",
    "work_dir = r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\mid-aud-to-midi-bearaudiotool.com-mp3-to-midi'\n",
    "\n",
    "x_train_data = []\n",
    "x_test_data =[]\n",
    "y_a_train_data = []\n",
    "y_a_test_data = []\n",
    "y_v_train_data = []\n",
    "y_v_test_data = []\n",
    "\n",
    "for parent, dirnames, filenames in os.walk(work_dir,  followlinks=True):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".mid\"):\n",
    "            index = os.path.splitext(os.path.splitext(filename)[0])[0]\n",
    "            if index in train_list:\n",
    "                (x_train_data,y_a_train_data,y_v_train_data)=extraFeature_midi_cnn(\n",
    "                        parent,filename,output_dir,\n",
    "                        x_train_data,y_a_train_data,y_v_train_data,\n",
    "                        arousal_dict,volence_dict,\n",
    "                        fs=100,num_frame=50)\n",
    "                print(x_train_data.shape,\"train\",index)\n",
    "            if index in test_list:\n",
    "                (x_test_data,y_a_test_data,y_v_test_data)=extraFeature_midi_cnn(\n",
    "                        parent,filename,output_dir,\n",
    "                        x_test_data,y_a_test_data,y_v_test_data,\n",
    "                        arousal_dict,volence_dict,\n",
    "                        fs=100,num_frame=50)\n",
    "                print(x_test_data.shape,\"test\",index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#save the midi+cnn\n",
    "\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "with open(r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\400-100-dataset\\midi_cnn.json', 'w+') as f:\n",
    "    json.dump({'x_train':x_train_data,\n",
    "               'x_test':x_test_data,\n",
    "               'y_a_train':y_a_train_data,\n",
    "               'y_a_test':y_a_test_data,\n",
    "               'y_v_train':y_v_train_data,\n",
    "               'y_v_test':y_v_test_data},f,cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#midi+crnn\n",
    "work_dir = r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\mid-aud-to-midi-bearaudiotool.com-mp3-to-midi'\n",
    "\n",
    "x_train_data = []\n",
    "x_test_data =[]\n",
    "y_a_train_data = []\n",
    "y_a_test_data = []\n",
    "y_v_train_data = []\n",
    "y_v_test_data = []\n",
    "\n",
    "for parent, dirnames, filenames in os.walk(work_dir,  followlinks=True):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".mid\"):\n",
    "            index = os.path.splitext(os.path.splitext(filename)[0])[0]\n",
    "            if index in train_list:\n",
    "                (x_train_data,y_a_train_data,y_v_train_data)=extraFeature_midi_cnn(\n",
    "                        parent,filename,output_dir,\n",
    "                        x_train_data,y_a_train_data,y_v_train_data,\n",
    "                        arousal_dict,volence_dict,\n",
    "                        fs=2,num_frame=1)\n",
    "                print(x_train_data.shape,\"train\",index)\n",
    "            if index in test_list:\n",
    "                (x_test_data,y_a_test_data,y_v_test_data)=extraFeature_midi_cnn(\n",
    "                        parent,filename,output_dir,\n",
    "                        x_test_data,y_a_test_data,y_v_test_data,\n",
    "                        arousal_dict,volence_dict,\n",
    "                        fs=2,num_frame=1)\n",
    "                print(x_test_data.shape,\"test\",index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#save the midi+cnn\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "with open(r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\400-100-dataset\\midi_crnn.json', 'w+') as f:\n",
    "    json.dump({'x_train':x_train_data,\n",
    "               'x_test':x_test_data,\n",
    "               'y_a_train':y_a_train_data,\n",
    "               'y_a_test':y_a_test_data,\n",
    "               'y_v_train':y_v_train_data,\n",
    "               'y_v_test':y_v_test_data},f,cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#validate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

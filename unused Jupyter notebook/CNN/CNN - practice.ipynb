{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# https://stackoverflow.com/questions/26646362/numpy-array-is-not-json-serializable\n",
    "with open(r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\mid-small_dataset\\arousal.json','r') as load_f:\n",
    "    y_arousal_data = json.load(load_f)\n",
    "    y_arousal_data = np.asarray(y_arousal_data[\"arousal\"])\n",
    "    \n",
    "with open(r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\mid-small_dataset\\volence.json','r') as load_f:\n",
    "    y_volence_data = json.load(load_f)\n",
    "    y_volence_data = np.asarray(y_volence_data[\"volence\"])\n",
    "    \n",
    "with open(r'C:\\Users\\Arnold\\Desktop\\4560\\CNN\\dataset\\mid-small_dataset\\midi.json','r') as load_f:\n",
    "    x_data = json.load(load_f)\n",
    "    x_data = np.asarray(x_data[\"midi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 50, 128, 1) (30000, 1) (30000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_data = x_data.reshape(30000,50,128,1)\n",
    "y_arousal_data=y_arousal_data.reshape(30000,1)\n",
    "y_volence_data=y_volence_data.reshape(30000,1)\n",
    "\n",
    "x_train_data = x_data[:3000,]\n",
    "y_train_arousal_data=y_arousal_data[:3000,]\n",
    "y_train_volence_data=y_volence_data[:3000,]\n",
    "\n",
    "\n",
    "print(x_data.shape,y_arousal_data.shape,y_volence_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = layers.Input((50, 128,1))\n",
    "\n",
    "x_2 =layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding=\"same\")(input_data)\n",
    "x_2 =layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding=\"same\")(x_2)\n",
    "x_2 =layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2),padding='valid')(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_2 = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding=\"same\")(x_2)\n",
    "arousal_2 = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding=\"same\")(arousal_2)\n",
    "arousal_2 = layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2),padding='valid')(arousal_2)\n",
    "\n",
    "arousal_2 = layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding=\"same\")(arousal_2)\n",
    "arousal_2 = layers.MaxPooling2D(pool_size=(3, 3),strides=(3, 3),padding='valid')(arousal_2)\n",
    "arousal_2 = layers.Dropout(0.25)(arousal_2)\n",
    "\n",
    "arousal_2 = layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding=\"same\")(arousal_2)\n",
    "arousal_2 = layers.MaxPooling2D(pool_size=(3, 3),strides=(3, 3),padding='valid')(arousal_2)\n",
    "arousal_2 = layers.Dropout(0.25)(arousal_2)\n",
    "\n",
    "arousal_2 = layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding=\"same\")(arousal_2)\n",
    "arousal_2 = layers.MaxPooling2D(pool_size=(1, 3),strides=(3, 3),padding='valid')(arousal_2)\n",
    "arousal_2 = layers.Dropout(0.25)(arousal_2)\n",
    "\n",
    "arousal_2 = layers.Flatten()(arousal_2)\n",
    "\n",
    "arousal_2 = layers.Dense(256)(arousal_2)\n",
    "arousal_2 = layers.Dropout(0.5)(arousal_2)\n",
    "\n",
    "arousal_2 = layers.Dense(256)(arousal_2)\n",
    "arousal_2 = layers.Dropout(0.5)(arousal_2)\n",
    "\n",
    "arousal_2 = layers.Dense(1)(arousal_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "volence_2 = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding=\"same\")(x_2)\n",
    "volence_2 = layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding=\"same\")(volence_2)\n",
    "volence_2 = layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2),padding='valid')(volence_2)\n",
    "\n",
    "volence_2 = layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding=\"same\")(volence_2)\n",
    "volence_2 = layers.MaxPooling2D(pool_size=(3, 3),strides=(3, 3),padding='valid')(volence_2)\n",
    "volence_2 = layers.Dropout(0.25)(volence_2)\n",
    "\n",
    "volence_2 = layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding=\"same\")(volence_2)\n",
    "volence_2 = layers.MaxPooling2D(pool_size=(3, 3),strides=(3, 3),padding='valid')(volence_2)\n",
    "volence_2 = layers.Dropout(0.25)(volence_2)\n",
    "\n",
    "volence_2 = layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding=\"same\")(volence_2)\n",
    "volence_2 = layers.MaxPooling2D(pool_size=(1, 3),strides=(3, 3),padding='valid')(volence_2)\n",
    "volence_2 = layers.Dropout(0.25)(volence_2)\n",
    "\n",
    "volence_2 = layers.Flatten()(volence_2)\n",
    "\n",
    "volence_2 = layers.Dense(256)(volence_2)\n",
    "volence_2 = layers.Dropout(0.5)(volence_2)\n",
    "\n",
    "volence_2 = layers.Dense(256)(volence_2)\n",
    "volence_2 = layers.Dropout(0.5)(volence_2)\n",
    "\n",
    "volence_2 = layers.Dense(1)(volence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = keras.Model(inputs=input_data, outputs=[arousal_2, volence_2])\n",
    "\n",
    "model_2.compile(loss = [\"mean_squared_error\",\"mean_squared_error\"], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2009 samples, validate on 991 samples\n",
      "Epoch 1/15\n",
      "2009/2009 [==============================] - 142s 71ms/sample - loss: 0.0307 - dense_8_loss: 0.0143 - dense_11_loss: 0.0164 - val_loss: 0.0878 - val_dense_8_loss: 0.0478 - val_dense_11_loss: 0.0421\n",
      "Epoch 2/15\n",
      "2009/2009 [==============================] - 140s 70ms/sample - loss: 0.0294 - dense_8_loss: 0.0144 - dense_11_loss: 0.0151 - val_loss: 0.0956 - val_dense_8_loss: 0.0419 - val_dense_11_loss: 0.0563\n",
      "Epoch 3/15\n",
      "2009/2009 [==============================] - 141s 70ms/sample - loss: 0.0289 - dense_8_loss: 0.0142 - dense_11_loss: 0.0146 - val_loss: 0.0841 - val_dense_8_loss: 0.0450 - val_dense_11_loss: 0.0410\n",
      "Epoch 4/15\n",
      "2009/2009 [==============================] - 142s 71ms/sample - loss: 0.0262 - dense_8_loss: 0.0120 - dense_11_loss: 0.0143 - val_loss: 0.0897 - val_dense_8_loss: 0.0443 - val_dense_11_loss: 0.0470\n",
      "Epoch 5/15\n",
      "2009/2009 [==============================] - 141s 70ms/sample - loss: 0.0255 - dense_8_loss: 0.0125 - dense_11_loss: 0.0129 - val_loss: 0.0852 - val_dense_8_loss: 0.0472 - val_dense_11_loss: 0.0395\n",
      "Epoch 6/15\n",
      "2009/2009 [==============================] - 142s 71ms/sample - loss: 0.0246 - dense_8_loss: 0.0124 - dense_11_loss: 0.0122 - val_loss: 0.0899 - val_dense_8_loss: 0.0400 - val_dense_11_loss: 0.0519\n",
      "Epoch 7/15\n",
      "2009/2009 [==============================] - 140s 70ms/sample - loss: 0.0228 - dense_8_loss: 0.0110 - dense_11_loss: 0.0118 - val_loss: 0.0803 - val_dense_8_loss: 0.0431 - val_dense_11_loss: 0.0394\n",
      "Epoch 8/15\n",
      "2009/2009 [==============================] - 142s 71ms/sample - loss: 0.0216 - dense_8_loss: 0.0103 - dense_11_loss: 0.0114 - val_loss: 0.0952 - val_dense_8_loss: 0.0546 - val_dense_11_loss: 0.0424\n",
      "Epoch 9/15\n",
      "2009/2009 [==============================] - 141s 70ms/sample - loss: 0.0243 - dense_8_loss: 0.0124 - dense_11_loss: 0.0119 - val_loss: 0.0789 - val_dense_8_loss: 0.0420 - val_dense_11_loss: 0.0385\n",
      "Epoch 10/15\n",
      "2009/2009 [==============================] - 145s 72ms/sample - loss: 0.0225 - dense_8_loss: 0.0119 - dense_11_loss: 0.0106 - val_loss: 0.0709 - val_dense_8_loss: 0.0357 - val_dense_11_loss: 0.0359\n",
      "Epoch 11/15\n",
      "2009/2009 [==============================] - 141s 70ms/sample - loss: 0.0222 - dense_8_loss: 0.0112 - dense_11_loss: 0.0110 - val_loss: 0.0744 - val_dense_8_loss: 0.0391 - val_dense_11_loss: 0.0366\n",
      "Epoch 12/15\n",
      "2009/2009 [==============================] - 142s 71ms/sample - loss: 0.0217 - dense_8_loss: 0.0105 - dense_11_loss: 0.0112 - val_loss: 0.0853 - val_dense_8_loss: 0.0414 - val_dense_11_loss: 0.0458\n",
      "Epoch 13/15\n",
      "2009/2009 [==============================] - 140s 70ms/sample - loss: 0.0205 - dense_8_loss: 0.0102 - dense_11_loss: 0.0104 - val_loss: 0.0763 - val_dense_8_loss: 0.0362 - val_dense_11_loss: 0.0416\n",
      "Epoch 14/15\n",
      "2009/2009 [==============================] - 140s 70ms/sample - loss: 0.0210 - dense_8_loss: 0.0108 - dense_11_loss: 0.0102 - val_loss: 0.0799 - val_dense_8_loss: 0.0428 - val_dense_11_loss: 0.0391\n",
      "Epoch 15/15\n",
      "2009/2009 [==============================] - 142s 71ms/sample - loss: 0.0200 - dense_8_loss: 0.0102 - dense_11_loss: 0.0098 - val_loss: 0.0839 - val_dense_8_loss: 0.0436 - val_dense_11_loss: 0.0430\n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(x_train_data,[y_train_arousal_data,y_train_volence_data], validation_split=0.33, epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-37f848b1a6a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# model.output_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mx_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mx_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "# input_shape = (16, 50, 128, 1)\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(layers.Conv2D(filters=8, kernel_size=3, activation='relu', padding=\"same\", input_shape=input_shape[1:]))\n",
    "# model.add(layers.BatchNormalization())\n",
    "# model.add(layers.Reshape((model.output_shape[1],model.output_shape[2]*model.output_shape[3])))\n",
    "# model.add(layers.Dense(8, activation='linear'))\n",
    "# model.add(layers.Bidirectional(layers.GRU(8,return_sequences = True,activation = 'tanh')))\n",
    "# model.add(layers.Dense(1, activation='linear'))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(1))\n",
    "\n",
    "# model.output_shape\n",
    "\n",
    "input_data = layers.Input((50, 128,1))\n",
    "x_1 = layers.Conv2D(filters=8, kernel_size=3, activation='relu', padding=\"same\")(input_data)\n",
    "x_1 = layers.BatchNormalization()(x_1)\n",
    "x_1 = layers.Reshape((50,1024))(x_1)\n",
    "\n",
    "arousal_1 = layers.Dense(8, activation='linear')(x_1)\n",
    "arousal_1 = layers.Bidirectional(layers.GRU(8,return_sequences = True,activation = 'tanh'))(arousal_1)\n",
    "arousal_1 = layers.Dense(1, activation='linear')(arousal_1)\n",
    "arousal_1 = layers.Flatten()(arousal_1)\n",
    "arousal_1 = layers.Dense(1)(arousal_1)\n",
    "\n",
    "volence_1 = layers.Dense(8, activation='linear')(x_1)\n",
    "volence_1 = layers.Bidirectional(layers.GRU(8,return_sequences = True,activation = 'tanh'))(volence_1)\n",
    "volence_1 = layers.Dense(1, activation='linear')(volence_1)\n",
    "\n",
    "\n",
    "model_1 = keras.Model(inputs=input_data, outputs=[arousal_1, volence_1])\n",
    "model_1.compile(loss = rmse, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
